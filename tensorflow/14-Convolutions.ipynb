{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_dataset(name='mnist'):\n",
    "    (train_ds, validation_ds, test_ds), ds_info = tfds.load(\n",
    "        name,\n",
    "        split=[\n",
    "              'train[:70%]',\n",
    "              'train[70%:]',\n",
    "              'test'\n",
    "        ],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
    "    validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
    "        \n",
    "    def process_images(image, label):\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "        image = tf.image.resize(image, (227, 227))\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    train_ds = (train_ds\n",
    "                      .map(process_images)\n",
    "                      .shuffle(buffer_size=train_ds_size)\n",
    "                      .batch(batch_size=32, drop_remainder=True))\n",
    "    test_ds = (test_ds\n",
    "                      .map(process_images)\n",
    "                      .shuffle(buffer_size=train_ds_size)\n",
    "                      .batch(batch_size=32, drop_remainder=True))\n",
    "    validation_ds = (validation_ds\n",
    "                      .map(process_images)\n",
    "                      .shuffle(buffer_size=train_ds_size)\n",
    "                      .batch(batch_size=32, drop_remainder=True))\n",
    "    \n",
    "    return (train_ds, validation_ds, test_ds), ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_valid, ds_test), ds_info = load_tf_dataset('cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), strides=(1, 1), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), strides=(1, 1), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), strides=(1, 1), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(32, (5, 5), strides=(1, 1), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filter_1, num_filter_2, num_filter_3, \\\n",
    "                     num_filter_4, num_filter_5, num_filter_6, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        self.conv1_1 = tf.keras.layers.Conv2D(num_filter_1, (1, 1), strides=1, \\\n",
    "                                              activation='relu', padding='SAME')\n",
    "        self.conv1_2 = tf.keras.layers.Conv2D(num_filter_2, (1, 1), strides=1, \\\n",
    "                                              activation='relu', padding='SAME')\n",
    "        self.maxpool1 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='SAME')\n",
    "        self.conv2_1 = tf.keras.layers.Conv2D(num_filter_3, (1, 1), strides=1, \\\n",
    "                                              activation='relu', padding='SAME')\n",
    "        self.conv2_2 = tf.keras.layers.Conv2D(num_filter_4, (3, 3), strides=1, \\\n",
    "                                              activation='relu', padding='SAME')\n",
    "        self.conv2_3 = tf.keras.layers.Conv2D(num_filter_5, (5, 5), strides=1, \\\n",
    "                                              activation='relu', padding='SAME')\n",
    "        self.conv2_4 = tf.keras.layers.Conv2D(num_filter_6, (1, 1), strides=1, \\\n",
    "                                              activation='relu', padding='SAME')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        conv1_1 = self.conv1_1(inputs)\n",
    "        conv1_2 = self.conv1_2(inputs)\n",
    "        maxpool1 = self.maxpool1(inputs)\n",
    "        conv2_1 = self.conv2_1(inputs)\n",
    "        conv2_2 = self.conv2_2(conv1_1)\n",
    "        conv2_3 = self.conv2_3(conv1_2)\n",
    "        conv2_4 = self.conv2_4(maxpool1)\n",
    "        output = tf.keras.layers.concatenate([conv2_1, conv2_2, conv2_3, conv2_4])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convolutional = partial(tf.keras.layers.Conv2D,\n",
    "                        padding='SAME',\n",
    "                        activation='relu')\n",
    "MaxPooling = partial(tf.keras.layers.MaxPool2D,\n",
    "                        pool_size=(3, 3),\n",
    "                        strides=(2, 2),\n",
    "                        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(227, 227, 3)),\n",
    "    Convolutional(64, kernel_size=(7, 7), strides=(2, 2)),\n",
    "    MaxPooling(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    Convolutional(64, kernel_size=(1, 1), strides=(1, 1)),\n",
    "    Convolutional(192, kernel_size=(3, 3), strides=(1, 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    MaxPooling(),\n",
    "    Inception(64, 128, 32, 32, 96, 16),\n",
    "    Inception(128, 192, 96, 64, 128, 32),\n",
    "    tf.keras.layers.AvgPool2D(pool_size=(3, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
